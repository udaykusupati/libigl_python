{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating JAX arrays\n",
    "\n",
    "## Declaring and manipulating\n",
    "\n",
    "JAX looks really similar to Numpy on several aspects (methods are very similar), although the main difference is that jnp arrays are *immutable* as the following examples show:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target array: [10  1  2  3  4  5  6  7  8  9]\n",
      "\n",
      "This does not work, instead we could use .at[] and .set() to create a copy of the array.\n",
      "Old array: [0 1 2 3 4 5 6 7 8 9]\n",
      "New array: [10  1  2  3  4  5  6  7  8  9]\n",
      "\n",
      "Let's have a look at the risen exception: '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable; perhaps you want jax.ops.index_update or jax.ops.index_add instead?.\n"
     ]
    }
   ],
   "source": [
    "# We can change elements using slices after instanciating the array\n",
    "npArr    = np.arange(10)\n",
    "npArr[0] = 10\n",
    "print(\"Target array: {}\\n\".format(npArr))\n",
    "\n",
    "jnpArr = jnp.arange(10)\n",
    "try:\n",
    "    jnpArr[0] = 10\n",
    "except Exception as e:\n",
    "    print(\"This does not work, instead we could use .at[] and .set() to create a copy of the array.\")\n",
    "    copiedJnpArr = jnpArr.at[0].set(10)\n",
    "    print(\"Old array: {}\".format(jnpArr))\n",
    "    print(\"New array: {}\\n\".format(copiedJnpArr))\n",
    "    \n",
    "    print(\"Let's have a look at the risen exception: {}.\".format(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old array: [0 1 2 3 4 5 6 7 8 9]\n",
      "New array, update 3:6: [0 1 2 0 0 0 6 7 8 9]\n",
      "New array, add 2 to index in 3:6: [0 1 2 5 6 7 6 7 8 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jax.ops import index, index_add, index_update\n",
    "\n",
    "# We now follow the above recommendation\n",
    "copiedJnpArrUpdate = index_update(jnpArr, index[3:6], 0.)\n",
    "copiedJnpArrAdd = index_add(jnpArr, index[3:6], 2.)\n",
    "print(\"Old array: {}\".format(jnpArr))\n",
    "print(\"New array, update 3:6: {}\".format(copiedJnpArrUpdate))\n",
    "print(\"New array, add 2 to index in 3:6: {}\\n\".format(copiedJnpArrAdd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of bound indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20-th element of the array of shape (10,) is: 9. For JAX arrays, out of bound indexing does not throw an exception, and rather return the last element of the array.\n"
     ]
    }
   ],
   "source": [
    "jnpArr = jnp.arange(10)\n",
    "print(\"The 20-th element of the array of shape (10,) is: {}. For JAX arrays, out of bound\".format(jnpArr[20]) +\n",
    "     \" indexing does not throw an exception, and rather return the last element of the array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JIT\n",
    "\n",
    "JIT stands for Just-In-Time, and acts as a decorator on a python method. JAX executes operations sequencially, and JIT tries to optimize the operations' execution time. However JIT has a limited scope which we will expose in the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT-able method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 µs ± 26.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "153 µs ± 5.72 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# First we give an example of a JIT-able method\n",
    "\n",
    "def MatMul(X, Y):\n",
    "    Z = jnp.dot(X, Y) # X @ Y is equivalent\n",
    "    return Z\n",
    "\n",
    "CompiledMatMul = jit(MatMul)\n",
    "\n",
    "np.random.seed(1)\n",
    "X = jnp.array(np.random.rand(100, 1000))\n",
    "Y = jnp.array(np.random.rand(1000, 100))\n",
    "\n",
    "%timeit MatMul(X, Y).block_until_ready()\n",
    "%timeit CompiledMatMul(X, Y).block_until_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running VerboseMatMul\n",
      "X is Traced<ShapedArray(float32[100,1000])>with<DynamicJaxprTrace(level=0/1)>\n",
      "Y is Traced<ShapedArray(float32[1000,100])>with<DynamicJaxprTrace(level=0/1)>\n",
      "Z is Traced<ShapedArray(float32[100,100])>with<DynamicJaxprTrace(level=0/1)>\n",
      "\n",
      "We can see a bunch of traced arrays with fixed shapes. Let's try to re-run thefunction that should now be compiled.\n",
      "\n",
      "The messages are not printed this time, as we now manipulate the compiled version of the method. We can have a look at the JAX expression of the function as follow:\n",
      "\n",
      "{ lambda  ; a b.\n",
      "  let c = dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n",
      "                       precision=None\n",
      "                       preferred_element_type=None ] a b\n",
      "  in (c,) }\n",
      "\n",
      "One last thing! If one of the input's shape changes, the function will be recompiled. This can be disastrous in case this shape varies a lot.\n",
      "\n",
      "Running VerboseMatMul\n",
      "X is Traced<ShapedArray(float32[101,1000])>with<DynamicJaxprTrace(level=0/1)>\n",
      "Y is Traced<ShapedArray(float32[1000,100])>with<DynamicJaxprTrace(level=0/1)>\n",
      "Z is Traced<ShapedArray(float32[101,100])>with<DynamicJaxprTrace(level=0/1)>\n"
     ]
    }
   ],
   "source": [
    "# We now inspect what's in the JITed function\n",
    "\n",
    "@jit\n",
    "def VerboseMatMul(X, Y):\n",
    "    print(\"Running VerboseMatMul\")\n",
    "    print(\"X is {}\".format(X))\n",
    "    print(\"Y is {}\".format(Y))\n",
    "    Z = jnp.dot(X, Y) # X @ Y is equivalent\n",
    "    print(\"Z is {}\".format(Z))\n",
    "    return Z\n",
    "\n",
    "Z = VerboseMatMul(X, Y)\n",
    "print(\"\\nWe can see a bunch of traced arrays with fixed shapes. Let's try to re-run the\"\n",
    "      + \"function that should now be compiled.\")\n",
    "\n",
    "Z = VerboseMatMul(X, Y)\n",
    "print(\"\\nThe messages are not printed this time, as we now manipulate the compiled version of the method.\"\n",
    "      + \" We can have a look at the JAX expression of the function as follow:\\n\")\n",
    "\n",
    "from jax import make_jaxpr\n",
    "\n",
    "print(make_jaxpr(MatMul)(X, Y))\n",
    "\n",
    "print(\"\\nOne last thing! If one of the input's shape changes, the function will be recompiled.\"+\n",
    "     \" This can be disastrous in case this shape varies a lot.\\n\")\n",
    "X1 = jnp.array(np.random.rand(101, 1000))\n",
    "Z = VerboseMatMul(X1, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un-JIT-able methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the non-compiled version of GetNegatives works, and returns: [-0.6117564  -0.5281718  -1.0729686  -2.3015387  -0.7612069  -0.24937038]\n",
      "\n",
      "However the compiled version does not accept indices having a shape that can vary (called non-concrete or abstract). The raised exception reads:\n",
      "\n",
      "Array boolean indices must be concrete; got ShapedArray(bool[10])\n",
      "\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError\n"
     ]
    }
   ],
   "source": [
    "# JITed methods must only manipulate arrays with static shapes\n",
    "\n",
    "def GetNegatives(x):\n",
    "    return x[x < 0]\n",
    "\n",
    "np.random.seed(1)\n",
    "x = jnp.array(np.random.randn(10))\n",
    "print(\"Using the non-compiled version of GetNegatives works, and returns: {}\".format(GetNegatives(x)))\n",
    "\n",
    "CompiledGetNegatives = jit(GetNegatives)\n",
    "\n",
    "try:\n",
    "    print(CompiledGetNegatives(x))\n",
    "except Exception as e:\n",
    "    print(\"\\nHowever the compiled version does not accept indices having a shape that can vary \" + \n",
    "          \"(called non-concrete or abstract). The raised exception reads:\\n\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the non-compiled version of TransformNegative works,and returns: \n",
      "[ 1.6243454  -0.6117564  -0.5281718  -1.0729686   0.86540765 -2.3015387\n",
      "  1.7448118  -0.7612069   0.3190391  -0.24937038]\n",
      "\n",
      "However the compiled version cannot have if statements that depend on the content of traced variables (which itself is not traced). The raised exception reads:\n",
      "\n",
      "Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[1])>with<DynamicJaxprTrace(level=0/1)>\n",
      "The problem arose with the `bool` function. \n",
      "While tracing the function TransformNegative at <ipython-input-49-8a8424009ac0>:1 for jit, this concrete value was not available in Python because it depends on the value of the argument 'thresh'.\n",
      "\n",
      "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError\n"
     ]
    }
   ],
   "source": [
    "def TransformNegative(x, thresh):\n",
    "    return x if thresh>0 else -x\n",
    "\n",
    "np.random.seed(1)\n",
    "x = jnp.array(np.random.randn(10))\n",
    "thresh = jnp.array(np.random.randn(1))\n",
    "print(\"Using the non-compiled version of TransformNegative works,\" +\n",
    "      \"and returns: \\n{}\".format(TransformNegative(x, thresh)))\n",
    "\n",
    "CompileTransformNegative = jit(TransformNegative)\n",
    "\n",
    "try:\n",
    "    print(CompileTransformNegative(x, thresh))\n",
    "except Exception as e:\n",
    "    print(\"\\nHowever the compiled version cannot have if statements that depend on the content of \" + \n",
    "          \"traced variables (which itself is not traced). Upon compilation, it should be clear\"+ \n",
    "          \" what if/else path is chosen. The raised exception reads:\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "We now show how functions can be vectorized using one of JAX's transforms: `vmap`. We reuse the example given in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the convolution: [11. 20. 29.]\n"
     ]
    }
   ],
   "source": [
    "# We start with a simple convolution function\n",
    "\n",
    "x = jnp.arange(5)\n",
    "w = jnp.array([2., 3., 4.])\n",
    "\n",
    "def convolve(x, w):\n",
    "    output = []\n",
    "    for i in range(1, len(x)-1):\n",
    "        # This assumes that w has shape (3,)\n",
    "        output.append(jnp.dot(x[i-1:i+2], w))\n",
    "    return jnp.array(output)\n",
    "\n",
    "print(\"Result of the convolution: {}\".format(convolve(x, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We naively create a vectorized version by looping over the batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we could use vmap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autodiff\n",
    "\n",
    "We now show some examples for taking derivatives of various orders.\n",
    "\n",
    "## First order: gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the loss: [0. 1. 2. 3.]\n",
      "Value and gradient of the loss: (DeviceArray(7., dtype=float32), DeviceArray([0., 1., 2., 3.], dtype=float32))\n",
      "Gradient of the loss with aux: ((DeviceArray(7., dtype=float32), DeviceArray([0., 1., 4., 9.], dtype=float32)), DeviceArray([0., 1., 2., 3.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "from jax import grad, value_and_grad\n",
    "\n",
    "x = jnp.arange(4, dtype=jnp.float32)\n",
    "\n",
    "@jit\n",
    "def SumSquaresLoss(x):\n",
    "    return .5 * jnp.sum(x**2)\n",
    "\n",
    "# Just the gradient\n",
    "GradSumSquaresLoss = grad(SumSquaresLoss)\n",
    "print(\"Gradient of the loss: {}\".format(GradSumSquaresLoss(x)))\n",
    "\n",
    "# Value and gradient\n",
    "ValGradSumSquaresLoss = value_and_grad(SumSquaresLoss)\n",
    "print(\"Value and gradient of the loss: {}\".format(ValGradSumSquaresLoss(x)))\n",
    "\n",
    "# If we now want to output a auxiliary result we can use the following\n",
    "@jit\n",
    "def SumSquaresLossWithAux(x):\n",
    "    return .5 * jnp.sum(x**2), x**2\n",
    "\n",
    "ValGradSumSquaresLossWithAux = value_and_grad(SumSquaresLossWithAux, has_aux=True)\n",
    "print(\"Value and gradient of the loss with aux: {}\".format(ValGradSumSquaresLossWithAux(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the loss wrt the first argument: [0. 1. 2. 3.]\n",
      "Gradient of the loss wrt both arguments: (DeviceArray([0., 1., 2., 3.], dtype=float32), DeviceArray([4., 5.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# We now show an example of a scalar function that takes to inputs\n",
    "\n",
    "x = jnp.arange(4, dtype=jnp.float32)\n",
    "y = jnp.arange(2, dtype=jnp.float32) + 4.\n",
    "\n",
    "@jit\n",
    "def SumSquaresLoss2(x, y):\n",
    "    return .5 * (jnp.sum(x**2) + jnp.sum(y**2))\n",
    "\n",
    "GradSumSquaresLoss2 = grad(SumSquaresLoss2)\n",
    "print(\"Gradient of the loss wrt the first argument: {}\".format(GradSumSquaresLoss2(x, y)))\n",
    "\n",
    "GradSumSquaresLossBoth2 = grad(SumSquaresLoss2, argnums=(0, 1))\n",
    "print(\"Gradient of the loss wrt both arguments: {}\".format(GradSumSquaresLossBoth2(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using grad on a function that outputs multiple variables yields a error. We get the following exception:\n",
      "\n",
      "Gradient only defined for scalar-output functions. Output had shape: (2,).\n"
     ]
    }
   ],
   "source": [
    "# Failure case\n",
    "A = jnp.arange(8, dtype=jnp.float32).reshape(2, 4)\n",
    "\n",
    "@jit\n",
    "def MulByA(x):\n",
    "    return jnp.dot(A, x)\n",
    "GradMulByA = grad(MulByA)\n",
    "\n",
    "try:\n",
    "    GradMulByA(x)\n",
    "except Exception as e:\n",
    "    print(\"Using grad on a function that outputs multiple variables yields a error.\" + \n",
    "         \" We get the following exception:\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First order: Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
